{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_augmented_cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbTyvRZPQ94A"
      },
      "source": [
        "# Augmented CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQW7ho3HRBsH",
        "outputId": "f353661c-49a6-41f3-e699-8fcc75180775"
      },
      "source": [
        "# Mount google drive to notebook to pull pickle files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZrcyxwVREQQ"
      },
      "source": [
        "# import libraries\n",
        "import time, scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Activation\n",
        "from sklearn.metrics import recall_score\n",
        "from tensorflow.keras import layers\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8oOZntoRVMG"
      },
      "source": [
        "# Open Pickle files containing train and test data\n",
        "infile = open('/content/drive/MyDrive/nsfw_image_classification/Pickles/X.pickle','rb')\n",
        "X = pickle.load(infile)\n",
        "\n",
        "infile2 = open('/content/drive/MyDrive/nsfw_image_classification/Pickles/y.pickle','rb')\n",
        "y = pickle.load(infile2)\n",
        "\n",
        "infile3 = open('/content/drive/MyDrive/nsfw_image_classification/Pickles/X_test.pickle','rb')\n",
        "X_test = pickle.load(infile3)\n",
        "\n",
        "infile4 = open('/content/drive/MyDrive/nsfw_image_classification/Pickles/y_test.pickle','rb')\n",
        "y_test = pickle.load(infile4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4NyNhV0TQh8"
      },
      "source": [
        "data_augmentation = Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dWUzB0nRZJg",
        "outputId": "c01b3f35-cf54-4d6e-8686-8000c32c3723"
      },
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape=X.shape[1:]),\n",
        "  layers.MaxPooling2D(pool_size=2, strides=2)\n",
        "])\n",
        "model.add(layers.Conv2D(filters=48, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=2, strides=2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# finally compile and train the cnn\n",
        "model.compile(optimizer=\"adam\", \n",
        "              loss=\"mse\", \n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X, \n",
        "          y, \n",
        "          epochs=10,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1618/1618 [==============================] - 764s 451ms/step - loss: 0.5993 - accuracy: 0.3764 - val_loss: 0.5963 - val_accuracy: 0.4746\n",
            "Epoch 2/10\n",
            "1618/1618 [==============================] - 713s 441ms/step - loss: 0.5993 - accuracy: 0.3793 - val_loss: 0.5963 - val_accuracy: 0.4866\n",
            "Epoch 3/10\n",
            "1618/1618 [==============================] - 741s 458ms/step - loss: 0.5993 - accuracy: 0.3830 - val_loss: 0.5963 - val_accuracy: 0.3665\n",
            "Epoch 4/10\n",
            "1618/1618 [==============================] - 749s 463ms/step - loss: 0.5993 - accuracy: 0.4002 - val_loss: 0.5963 - val_accuracy: 0.4856\n",
            "Epoch 5/10\n",
            "1618/1618 [==============================] - 747s 462ms/step - loss: 0.5993 - accuracy: 0.4214 - val_loss: 0.5963 - val_accuracy: 0.3776\n",
            "Epoch 6/10\n",
            "1618/1618 [==============================] - 731s 452ms/step - loss: 0.5993 - accuracy: 0.4148 - val_loss: 0.5963 - val_accuracy: 0.4873\n",
            "Epoch 7/10\n",
            "1618/1618 [==============================] - 726s 449ms/step - loss: 0.5993 - accuracy: 0.3867 - val_loss: 0.5963 - val_accuracy: 0.4855\n",
            "Epoch 8/10\n",
            "1618/1618 [==============================] - 712s 440ms/step - loss: 0.5993 - accuracy: 0.4101 - val_loss: 0.5963 - val_accuracy: 0.1379\n",
            "Epoch 9/10\n",
            "1618/1618 [==============================] - 707s 437ms/step - loss: 0.5993 - accuracy: 0.3941 - val_loss: 0.5963 - val_accuracy: 0.4855\n",
            "Epoch 10/10\n",
            "1618/1618 [==============================] - 713s 441ms/step - loss: 0.5993 - accuracy: 0.3814 - val_loss: 0.5963 - val_accuracy: 0.4876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9cfcf19d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_15Bnq_bhnMA"
      },
      "source": [
        "This model is still oscillating around 48% arfter image augmentation. It is possible that my small image size of 80x80 may be negatively impacting my model performance. After further research I have learned that standard image size for CNN models is 256x256. Some people may use standard sets as large as 512x512. If 512x512 is optimal, my current image size is 1/6 of what it needs to be."
      ]
    }
  ]
}